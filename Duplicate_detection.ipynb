{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Question 5</h1>\n",
    "<br>Duplicate Detection/Minhash in cookbook_txt.<br>\n",
    "<b> NOTE: All the code is executed in databricks due to memory issues in jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import *\n",
    "import re\n",
    "\n",
    "sc = SparkContext()\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#convorting the regular expressions\n",
    "def get_exp(pairs):\n",
    "    line = re.sub(r'\\n\\s*\\n','\\n',pairs[1],re.MULTILINE)\n",
    "    return [[[exp for exp in pairs[0].split('/')][-1] ,line]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Making an rdd by applying functions to all files in the folder\n",
    "data_docs = sc.wholeTextFiles(\"/FileStore/tables/*.txt\").flatMap(get_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+--------------------+\n",
       "doc_name|              recipe|\n",
       "+--------+--------------------+\n",
       "amem.txt| \n",
       " The American M...|\n",
       "amwh.txt| \r\n",
       "  The American...|\n",
       "army.txt| \r\n",
       " Manual For Ar...|\n",
       "aunt.txt| \r\n",
       "  &#34;Aunt Babett...|\n",
       "bart.txt| \r\n",
       " THE \r\n",
       "IDEAL B...|\n",
       "beec.txt| \r\n",
       "    A bookplat...|\n",
       "blue.txt| \r\n",
       " THE BLUE GRAS...|\n",
       "bost.txt| \r\n",
       " THE  BOSTON C...|\n",
       "brkf.txt| \r\n",
       " Breakfast, Lu...|\n",
       "buck.txt| \r\n",
       " Practical  Ho...|\n",
       "cclu.txt| \r\n",
       "   Cooking in ...|\n",
       "chas.txt| \r\n",
       " Dr. Chase&#39;s R...|\n",
       "chin.txt| \r\n",
       " Chinese-Japan...|\n",
       "choc.txt| \r\n",
       " Chocolate and...|\n",
       "comm.txt| \r\n",
       " Common Sense ...|\n",
       "conf.txt| \r\n",
       " The Complete ...|\n",
       "coow.txt| \r\n",
       " The Cook&#39;s Ow...|\n",
       "creo.txt| \r\n",
       " La Cuisine Cr...|\n",
       "dcvb.txt| \r\n",
       " Directions fo...|\n",
       "dish.txt| \r\n",
       "  Dishes &amp;amp;...|\n",
       "+--------+--------------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Convorting the rdd to a dataframe for further processing\n",
    "docs_info = data_docs.toDF(['doc_name','recipe'])\n",
    "docs_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+--------------------+--------------------+\n",
       "doc_name|              recipe|              tokens|\n",
       "+--------+--------------------+--------------------+\n",
       "amem.txt| \n",
       " The American M...|[, , , the, ameri...|\n",
       "amwh.txt| \r\n",
       "  The American...|[, , , , , the, a...|\n",
       "army.txt| \r\n",
       " Manual For Ar...|[, , , , manual, ...|\n",
       "aunt.txt| \r\n",
       "  &#34;Aunt Babett...|[, , , , , &#34;aunt,...|\n",
       "bart.txt| \r\n",
       " THE \r\n",
       "IDEAL B...|[, , , , the, , ,...|\n",
       "beec.txt| \r\n",
       "    A bookplat...|[, , , , , , , a,...|\n",
       "blue.txt| \r\n",
       " THE BLUE GRAS...|[, , , , the, blu...|\n",
       "bost.txt| \r\n",
       " THE  BOSTON C...|[, , , , the, , b...|\n",
       "brkf.txt| \r\n",
       " Breakfast, Lu...|[, , , , breakfas...|\n",
       "buck.txt| \r\n",
       " Practical  Ho...|[, , , , practica...|\n",
       "cclu.txt| \r\n",
       "   Cooking in ...|[, , , , , , cook...|\n",
       "chas.txt| \r\n",
       " Dr. Chase&#39;s R...|[, , , , dr., cha...|\n",
       "chin.txt| \r\n",
       " Chinese-Japan...|[, , , , chinese-...|\n",
       "choc.txt| \r\n",
       " Chocolate and...|[, , , , chocolat...|\n",
       "comm.txt| \r\n",
       " Common Sense ...|[, , , , common, ...|\n",
       "conf.txt| \r\n",
       " The Complete ...|[, , , , the, com...|\n",
       "coow.txt| \r\n",
       " The Cook&#39;s Ow...|[, , , , the, coo...|\n",
       "creo.txt| \r\n",
       " La Cuisine Cr...|[, , , , la, cuis...|\n",
       "dcvb.txt| \r\n",
       " Directions fo...|[, , , , directio...|\n",
       "dish.txt| \r\n",
       "  Dishes &amp;amp;...|[, , , , , dishes...|\n",
       "+--------+--------------------+--------------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#creating tokens and showing the tokenized data along with the prev data This gives us a set of values we can compare.\n",
    "tokens = Tokenizer(inputCol=\"recipe\", outputCol=\"tokens\")\n",
    "tokenized_data = tokens.transform(docs_info)\n",
    "tokenized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+--------------------+--------------------+--------------------+\n",
       "doc_name|              recipe|              tokens|            shingles|\n",
       "+--------+--------------------+--------------------+--------------------+\n",
       "amem.txt| \n",
       " The American M...|[, , , the, ameri...|[ ,  ,  the, the ...|\n",
       "amwh.txt| \r\n",
       "  The American...|[, , , , , the, a...|[ ,  ,  ,  ,  the...|\n",
       "army.txt| \r\n",
       " Manual For Ar...|[, , , , manual, ...|[ ,  ,  ,  manual...|\n",
       "aunt.txt| \r\n",
       "  &#34;Aunt Babett...|[, , , , , &#34;aunt,...|[ ,  ,  ,  ,  &#34;au...|\n",
       "bart.txt| \r\n",
       " THE \r\n",
       "IDEAL B...|[, , , , the, , ,...|[ ,  ,  ,  the, t...|\n",
       "beec.txt| \r\n",
       "    A bookplat...|[, , , , , , , a,...|[ ,  ,  ,  ,  ,  ...|\n",
       "blue.txt| \r\n",
       " THE BLUE GRAS...|[, , , , the, blu...|[ ,  ,  ,  the, t...|\n",
       "bost.txt| \r\n",
       " THE  BOSTON C...|[, , , , the, , b...|[ ,  ,  ,  the, t...|\n",
       "brkf.txt| \r\n",
       " Breakfast, Lu...|[, , , , breakfas...|[ ,  ,  ,  breakf...|\n",
       "buck.txt| \r\n",
       " Practical  Ho...|[, , , , practica...|[ ,  ,  ,  practi...|\n",
       "cclu.txt| \r\n",
       "   Cooking in ...|[, , , , , , cook...|[ ,  ,  ,  ,  ,  ...|\n",
       "chas.txt| \r\n",
       " Dr. Chase&#39;s R...|[, , , , dr., cha...|[ ,  ,  ,  dr., d...|\n",
       "chin.txt| \r\n",
       " Chinese-Japan...|[, , , , chinese-...|[ ,  ,  ,  chines...|\n",
       "choc.txt| \r\n",
       " Chocolate and...|[, , , , chocolat...|[ ,  ,  ,  chocol...|\n",
       "comm.txt| \r\n",
       " Common Sense ...|[, , , , common, ...|[ ,  ,  ,  common...|\n",
       "conf.txt| \r\n",
       " The Complete ...|[, , , , the, com...|[ ,  ,  ,  the, t...|\n",
       "coow.txt| \r\n",
       " The Cook&#39;s Ow...|[, , , , the, coo...|[ ,  ,  ,  the, t...|\n",
       "creo.txt| \r\n",
       " La Cuisine Cr...|[, , , , la, cuis...|[ ,  ,  ,  la, la...|\n",
       "dcvb.txt| \r\n",
       " Directions fo...|[, , , , directio...|[ ,  ,  ,  direct...|\n",
       "dish.txt| \r\n",
       "  Dishes &amp;amp;...|[, , , , , dishes...|[ ,  ,  ,  ,  dis...|\n",
       "+--------+--------------------+--------------------+--------------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Making shingles using NGram\n",
    "n_grams = NGram(n=2, inputCol=\"tokens\", outputCol=\"shingles\")\n",
    "shingled_data = n_grams.transform(tokenized_data)\n",
    "shingled_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+--------------------+--------------------+--------------------+--------------------+\n",
       "doc_name|              recipe|              tokens|            shingles|     shingle_vectors|\n",
       "+--------+--------------------+--------------------+--------------------+--------------------+\n",
       "amem.txt| \n",
       " The American M...|[, , , the, ameri...|[ ,  ,  the, the ...|(10000,[0,4,21,21...|\n",
       "amwh.txt| \r\n",
       "  The American...|[, , , , , the, a...|[ ,  ,  ,  ,  the...|(10000,[0,1,2,3,4...|\n",
       "army.txt| \r\n",
       " Manual For Ar...|[, , , , manual, ...|[ ,  ,  ,  manual...|(10000,[0,1,2,3,4...|\n",
       "aunt.txt| \r\n",
       "  &#34;Aunt Babett...|[, , , , , &#34;aunt,...|[ ,  ,  ,  ,  &#34;au...|(10000,[0,1,2,3,4...|\n",
       "bart.txt| \r\n",
       " THE \r\n",
       "IDEAL B...|[, , , , the, , ,...|[ ,  ,  ,  the, t...|(10000,[0,1,2,3,4...|\n",
       "beec.txt| \r\n",
       "    A bookplat...|[, , , , , , , a,...|[ ,  ,  ,  ,  ,  ...|(10000,[0,1,2,3,4...|\n",
       "blue.txt| \r\n",
       " THE BLUE GRAS...|[, , , , the, blu...|[ ,  ,  ,  the, t...|(10000,[0,1,2,3,4...|\n",
       "bost.txt| \r\n",
       " THE  BOSTON C...|[, , , , the, , b...|[ ,  ,  ,  the, t...|(10000,[0,1,2,3,4...|\n",
       "brkf.txt| \r\n",
       " Breakfast, Lu...|[, , , , breakfas...|[ ,  ,  ,  breakf...|(10000,[0,1,2,3,4...|\n",
       "buck.txt| \r\n",
       " Practical  Ho...|[, , , , practica...|[ ,  ,  ,  practi...|(10000,[0,1,2,3,4...|\n",
       "cclu.txt| \r\n",
       "   Cooking in ...|[, , , , , , cook...|[ ,  ,  ,  ,  ,  ...|(10000,[0,1,2,3,4...|\n",
       "chas.txt| \r\n",
       " Dr. Chase&#39;s R...|[, , , , dr., cha...|[ ,  ,  ,  dr., d...|(10000,[0,1,2,3,4...|\n",
       "chin.txt| \r\n",
       " Chinese-Japan...|[, , , , chinese-...|[ ,  ,  ,  chines...|(10000,[0,1,2,3,4...|\n",
       "choc.txt| \r\n",
       " Chocolate and...|[, , , , chocolat...|[ ,  ,  ,  chocol...|(10000,[0,1,2,3,4...|\n",
       "comm.txt| \r\n",
       " Common Sense ...|[, , , , common, ...|[ ,  ,  ,  common...|(10000,[0,1,2,3,4...|\n",
       "conf.txt| \r\n",
       " The Complete ...|[, , , , the, com...|[ ,  ,  ,  the, t...|(10000,[0,1,2,3,4...|\n",
       "coow.txt| \r\n",
       " The Cook&#39;s Ow...|[, , , , the, coo...|[ ,  ,  ,  the, t...|(10000,[0,1,2,3,4...|\n",
       "creo.txt| \r\n",
       " La Cuisine Cr...|[, , , , la, cuis...|[ ,  ,  ,  la, la...|(10000,[0,1,2,3,4...|\n",
       "dcvb.txt| \r\n",
       " Directions fo...|[, , , , directio...|[ ,  ,  ,  direct...|(10000,[0,1,2,3,4...|\n",
       "dish.txt| \r\n",
       "  Dishes &amp;amp;...|[, , , , , dishes...|[ ,  ,  ,  ,  dis...|(10000,[0,1,2,3,4...|\n",
       "+--------+--------------------+--------------------+--------------------+--------------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Vectorizing the shingles\n",
    "shingles_vec = CountVectorizer(inputCol=\"shingles\", outputCol=\"shingle_vectors\", vocabSize=10000, minDF=2.0)\n",
    "model = shingles_vec.fit(shingled_data)\n",
    "shingled_data = model.transform(shingled_data)\n",
    "shingled_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
       "doc_name|              recipe|              tokens|            shingles|     shingle_vectors|              hashes|\n",
       "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
       "amem.txt| \n",
       " The American M...|[, , , the, ameri...|[ ,  ,  the, the ...|(10000,[0,4,21,21...|[[5.9439856E7], [...|\n",
       "amwh.txt| \r\n",
       "  The American...|[, , , , , the, a...|[ ,  ,  ,  ,  the...|(10000,[0,1,2,3,4...|[[784957.0], [157...|\n",
       "army.txt| \r\n",
       " Manual For Ar...|[, , , , manual, ...|[ ,  ,  ,  manual...|(10000,[0,1,2,3,4...|[[482803.0], [659...|\n",
       "aunt.txt| \r\n",
       "  &#34;Aunt Babett...|[, , , , , &#34;aunt,...|[ ,  ,  ,  ,  &#34;au...|(10000,[0,1,2,3,4...|[[106485.0], [157...|\n",
       "bart.txt| \r\n",
       " THE \r\n",
       "IDEAL B...|[, , , , the, , ,...|[ ,  ,  ,  the, t...|(10000,[0,1,2,3,4...|[[973116.0], [375...|\n",
       "beec.txt| \r\n",
       "    A bookplat...|[, , , , , , , a,...|[ ,  ,  ,  ,  ,  ...|(10000,[0,1,2,3,4...|[[106485.0], [157...|\n",
       "blue.txt| \r\n",
       " THE BLUE GRAS...|[, , , , the, blu...|[ ,  ,  ,  the, t...|(10000,[0,1,2,3,4...|[[294644.0], [157...|\n",
       "bost.txt| \r\n",
       " THE  BOSTON C...|[, , , , the, , b...|[ ,  ,  ,  the, t...|(10000,[0,1,2,3,4...|[[106485.0], [157...|\n",
       "brkf.txt| \r\n",
       " Breakfast, Lu...|[, , , , breakfas...|[ ,  ,  ,  breakf...|(10000,[0,1,2,3,4...|[[106485.0], [157...|\n",
       "buck.txt| \r\n",
       " Practical  Ho...|[, , , , practica...|[ ,  ,  ,  practi...|(10000,[0,1,2,3,4...|[[482803.0], [157...|\n",
       "cclu.txt| \r\n",
       "   Cooking in ...|[, , , , , , cook...|[ ,  ,  ,  ,  ,  ...|(10000,[0,1,2,3,4...|[[482803.0], [659...|\n",
       "chas.txt| \r\n",
       " Dr. Chase&#39;s R...|[, , , , dr., cha...|[ ,  ,  ,  dr., d...|(10000,[0,1,2,3,4...|[[482803.0], [157...|\n",
       "chin.txt| \r\n",
       " Chinese-Japan...|[, , , , chinese-...|[ ,  ,  ,  chines...|(10000,[0,1,2,3,4...|[[106485.0], [120...|\n",
       "choc.txt| \r\n",
       " Chocolate and...|[, , , , chocolat...|[ ,  ,  ,  chocol...|(10000,[0,1,2,3,4...|[[482803.0], [157...|\n",
       "comm.txt| \r\n",
       " Common Sense ...|[, , , , common, ...|[ ,  ,  ,  common...|(10000,[0,1,2,3,4...|[[106485.0], [157...|\n",
       "conf.txt| \r\n",
       " The Complete ...|[, , , , the, com...|[ ,  ,  ,  the, t...|(10000,[0,1,2,3,4...|[[482803.0], [659...|\n",
       "coow.txt| \r\n",
       " The Cook&#39;s Ow...|[, , , , the, coo...|[ ,  ,  ,  the, t...|(10000,[0,1,2,3,4...|[[106485.0], [157...|\n",
       "creo.txt| \r\n",
       " La Cuisine Cr...|[, , , , la, cuis...|[ ,  ,  ,  la, la...|(10000,[0,1,2,3,4...|[[106485.0], [430...|\n",
       "dcvb.txt| \r\n",
       " Directions fo...|[, , , , directio...|[ ,  ,  ,  direct...|(10000,[0,1,2,3,4...|[[294644.0], [157...|\n",
       "dish.txt| \r\n",
       "  Dishes &amp;amp;...|[, , , , , dishes...|[ ,  ,  ,  ,  dis...|(10000,[0,1,2,3,4...|[[294644.0], [659...|\n",
       "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#generating hash signatures using the min_hash algorithm \n",
    "min_hash = MinHashLSH(inputCol=\"shingle_vectors\", outputCol=\"hashes\", seed=12345, numHashTables=3)\n",
    "model = min_hash.fit(shingled_data)\n",
    "hashed_data = model.transform(shingled_data)\n",
    "hashed_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using approx similarity join for self joining and finding the distances among the document data\n",
    "distances_val = model.approxSimilarityJoin(hashed_data, hashed_data, 3.0, distCol=\"eucDistance\").select(col(\"datasetA.doc_name\").alias(\"docA\"),col(\"datasetB.doc_name\").alias(\"docB\"),col(\"eucDistance\")).sort(desc(\"eucDistance\")).dropDuplicates(['eucDistance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+--------+------------------+\n",
       "    docA|    docB|       eucDistance|\n",
       "+--------+--------+------------------+\n",
       "notm.txt|bart.txt|0.8456949691787632|\n",
       "time.txt|bart.txt|0.8545218145044785|\n",
       "amwh.txt|fish.txt|0.7508479802651866|\n",
       "zuni.txt|fran.txt|0.7659010600706714|\n",
       "cclu.txt|youn.txt|0.7332290852228303|\n",
       "army.txt|mary.txt|0.7342608206857786|\n",
       "buck.txt|mary.txt|0.7342681654884691|\n",
       "choc.txt|fran.txt| 0.726149752945648|\n",
       "amwh.txt|fran.txt|0.7296062992125985|\n",
       "chin.txt|choc.txt|0.7083247262962198|\n",
       "+--------+--------+------------------+\n",
       "only showing top 10 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Displaying the top 5 rows due to memory issues\n",
    "distances_val.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+--------+------------------+\n",
       "    docA|    docB|       eucDistance|\n",
       "+--------+--------+------------------+\n",
       "notm.txt|bart.txt|0.8456949691787632|\n",
       "time.txt|bart.txt|0.8545218145044785|\n",
       "amwh.txt|fish.txt|0.7508479802651866|\n",
       "zuni.txt|fran.txt|0.7659010600706714|\n",
       "cclu.txt|youn.txt|0.7332290852228303|\n",
       "+--------+--------+------------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#setting a threshold of 0.7 and filtering out the values over the threshold.\n",
    "#Displaying the top 5 rows due to memory issues\n",
    "threshold = 0.7\n",
    "duplicates = distances_val.filter(distances_val['eucDistance'] > threshold)\n",
    "duplicates.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "Q5",
  "notebookId": 4071611460351895
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
